{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_auc_score,log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date company                                               news  \\\n",
      "0 2019-01-14     HCL  HCL Tech Q3 PAT seen up 4.2% QoQ to Rs. 2,629....   \n",
      "1 2018-12-07     HCL  HCL Technologies-IBM deal fails to enthuse inv...   \n",
      "2 2018-12-06     HCL  Technical Views | Top buy & sell ideas by Ashw...   \n",
      "3 2018-11-09     HCL  HCL Technologies Limited Q2 FY’19 Earnings Con...   \n",
      "4 2018-10-29     HCL  Buy HCL Technologies, target Rs 1182: Anand Rathi   \n",
      "5 2018-10-24     HCL  HCL Technologies – good outlook backed by reas...   \n",
      "6 2018-10-23     HCL  HCL Technologies sees 5.7% sequential rise in ...   \n",
      "7 2018-10-22     HCL  HCL Technologies Q2 results on October 23; her...   \n",
      "8 2018-10-15     HCL  Stock Picks of the Day | Nifty may be vulnerab...   \n",
      "9 2018-10-08     HCL  HCL Tech to set up global IT centres in Andhra...   \n",
      "\n",
      "   loss/profit   %change                                     Processed_news  \n",
      "0            0 -0.472399   hcl tech q3 pat see up 4 2 % qoq 7 dolat capital  \n",
      "1            0 -3.941059  hcl technology - ibm deal investor hcl tech ’ ...  \n",
      "2            0 -3.614630  view top buy & amp ; sell idea ashwani gujral ...  \n",
      "3            0 -0.097087  hcl technology limit q2 fy ’ 19 earning confer...  \n",
      "4            1  2.113990              buy hcl technology target anand rathi  \n",
      "5            1  0.775154  hcl technology – good outlook back valuation h...  \n",
      "6            0 -1.778350  hcl technology see 5 7 % rise q2 net profit crore  \n",
      "7            1  2.088542  hcl technology q2 result october 23 key thing ...  \n",
      "8            1  1.833232  stock pick day nifty may short term 3 stock li...  \n",
      "9            0 -0.097674  hcl tech set up global -PRON- centre andhra cr...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('D:\\\\DBDA Project\\\\Excels\\\\AllDataProcessed2.xlsx')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Processed_news\"]\n",
    "y = data[\"loss/profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to call various Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_features(X, y, clf=None):\n",
    "    \"\"\"General helper function for evaluating effectiveness of passed features in ML model\n",
    "    \n",
    "    Prints out Log loss, accuracy, and confusion matrix with 3-fold stratified cross-validation\n",
    "    \n",
    "    Args:\n",
    "        X (array-like): Features array. Shape (n_samples, n_features)\n",
    "        \n",
    "        y (array-like): Labels array. Shape (n_samples,)\n",
    "        \n",
    "        clf: Classifier to use. If None, default Log reg is use.\n",
    "    \"\"\"\n",
    "    if clf is None:\n",
    "        clf = LogisticRegression()\n",
    "    \n",
    "    probas = cross_val_predict(clf, X, y, cv=KFold(random_state=2019,n_splits=6), \n",
    "                              n_jobs=-1, method='predict_proba')\n",
    "    pred_indices = np.argmax(probas, axis=1)\n",
    "    classes = np.unique(y)\n",
    "    preds = classes[pred_indices]\n",
    "    print('Log loss: {}'.format(log_loss(y, probas)))\n",
    "    print('Accuracy: {}'.format(accuracy_score(y, preds)))\n",
    "    print('Classification report',classification_report(y,preds))\n",
    "    print('Confusion Matrix  ', confusion_matrix(y,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38525"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))  \n",
    "\n",
    "bag_of_words = count_vectorizer.fit_transform(data['Processed_news'])\n",
    "    \n",
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.7995815259357771\n",
      "Accuracy: 0.5456415809420683\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.57      4738\n",
      "           1       0.54      0.51      0.52      4497\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      9235\n",
      "   macro avg       0.54      0.54      0.54      9235\n",
      "weighted avg       0.55      0.55      0.55      9235\n",
      "\n",
      "Confusion Matrix   [[2757 1981]\n",
      " [2215 2282]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(bag_of_words, data['loss/profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.6900467547121742\n",
      "Accuracy: 0.5405522468868436\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.82      0.65      4738\n",
      "           1       0.56      0.25      0.35      4497\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      9235\n",
      "   macro avg       0.55      0.53      0.50      9235\n",
      "weighted avg       0.55      0.54      0.50      9235\n",
      "\n",
      "Confusion Matrix   [[3873  865]\n",
      " [3378 1119]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(bag_of_words, data['loss/profit'], \n",
    "                  RandomForestClassifier(n_estimators=300, max_depth=30,random_state=2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.6894828005718083\n",
      "Accuracy: 0.5390362750406064\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63      4738\n",
      "           1       0.55      0.31      0.39      4497\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      9235\n",
      "   macro avg       0.54      0.53      0.51      9235\n",
      "weighted avg       0.54      0.54      0.51      9235\n",
      "\n",
      "Confusion Matrix   [[3591 1147]\n",
      " [3110 1387]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(bag_of_words, data['loss/profit'],SVC(kernel='linear',probability=True,random_state=2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1749"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = TfidfVectorizer()    \n",
    "\n",
    "tfidf = count_vectorizer.fit_transform(data['Processed_news'])\n",
    "\n",
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.7009660189832868\n",
      "Accuracy: 0.5378451543042772\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57      4738\n",
      "           1       0.53      0.48      0.50      4497\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      9235\n",
      "   macro avg       0.54      0.54      0.54      9235\n",
      "weighted avg       0.54      0.54      0.54      9235\n",
      "\n",
      "Confusion Matrix   [[2792 1946]\n",
      " [2322 2175]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(tfidf, data['loss/profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.6894071945901016\n",
      "Accuracy: 0.5356794802382241\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.72      0.62      4738\n",
      "           1       0.54      0.34      0.41      4497\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      9235\n",
      "   macro avg       0.54      0.53      0.51      9235\n",
      "weighted avg       0.54      0.54      0.52      9235\n",
      "\n",
      "Confusion Matrix   [[3434 1304]\n",
      " [2984 1513]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(tfidf, data['loss/profit'], SVC(kernel='linear', probability=True, random_state=2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.6897448911893616\n",
      "Accuracy: 0.5431510557661072\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64      4738\n",
      "           1       0.56      0.30      0.39      4497\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      9235\n",
      "   macro avg       0.55      0.54      0.51      9235\n",
      "weighted avg       0.55      0.54      0.51      9235\n",
      "\n",
      "Confusion Matrix   [[3689 1049]\n",
      " [3170 1327]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(tfidf, data['loss/profit'], SVC(kernel='rbf', probability=True, random_state=45,C=2,gamma=.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8907, 58111)\n"
     ]
    }
   ],
   "source": [
    "basictf= TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),sublinear_tf=True)\n",
    "basicTrain=basictf.fit_transform(X_train)\n",
    "print(basicTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(basicTrain, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.002\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 32\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 20\n",
    "params['max_bin']=1024\n",
    "clf = lgb.train(params, d_train,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42222875, 0.48595289, 0.44494029, ..., 0.51849818, 0.41840873,\n",
       "       0.48488979])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicTest = basictf.transform(X_test)\n",
    "y_pred = clf.predict(basicTest)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2227):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[770 366]\n",
      " [653 438]]\n",
      "0.5424337674000899\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
